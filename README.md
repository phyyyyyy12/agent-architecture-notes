# agent-architecture-notes
深入解析 LLM 认知架构：从 CoT、ReAct、ToT 到 Reflexion 与 RL 的演进闭环
### 📝 今日“神经权重更新”总结报告
#### 1. 核心概念层级图 (俄罗斯套娃)

所有的概念其实是层层递进的，不是孤立的：

* **基座 (Base):** **LLM** (大模型本身)
* **第一层 (脑):** **CoT (思维链)**  让模型**把话说清楚**，显式写出逻辑。
* *JD 考点:* 会写 Prompt，懂 "Let's think step by step"。


* **第二层 (手):** **ReAct (推理+行动)**  CoT + **工具调用 (Tools)**。
* *JD 考点:* 会写代码循环，让 AI 联网、查库、调 API。


* **第三层 (网):** **ToT (思维树)**  多路 CoT + **评估与回溯 (Search)**。
* *JD 考点:* 懂算法 (DFS/BFS)，能解决复杂推理难题。


* **第四层 (镜):** **Reflexion (自我反思)**  失败后**看报错** + 存入**记忆 (RAG)**。
* *JD 考点:* 懂如何提升成功率，懂长短期记忆管理。


* **外挂 (锁):** **HITL (Human in the Loop)**  关键时刻**按暂停**，让人类确认。
* *JD 考点:* 懂安全，懂系统交互设计。



#### 2. 工程与学术的“翻译对照”

| 概念 | 本质是啥？ | 为什么 JD 要写？ | 实际工程里的样子 |
| --- | --- | --- | --- |
| **CoT** | **说话方式** | 它是最基本的 Prompt 技巧。 | `System: Please explain your reasoning...` |
| **ReAct** | **循环结构** | 代表你有开发 Agent 的能力。 | `while True: think() -> act() -> observe()` |
| **ToT** | **搜索算法** | 代表能处理高难度任务。 | 生成 A/B/C 三个方案，不要的剪掉，好的留下。 |
| **Reflexion** | **打补丁** | 代表能做自我纠错系统。 | 存一张“反思小纸条”到数据库，下次别犯错。 |
| **RL** | **系统升级** | 代表能训练模型。 | 把“反思后的正确数据”喂给模型，把补丁变成直觉。 |

#### 3. 终极心法：AI 进化的闭环

1. **Reflexion (短期):** 靠 Prompt 和 数据库（RAG）让模型在**推理时**变强（不改权重，只加记忆）。
2. **Data Gen:** 把 Reflexion 跑出来的成功案例存下来，变成数据。
3. **RL/SFT (长期):** 把数据喂给模型进行**训练**（修改权重）。
4. **Result:** 笨小孩通过记笔记（Reflexion）最后变成了天才（RL），不需要笔记也能考满分。

---
